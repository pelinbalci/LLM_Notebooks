{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca31e44",
   "metadata": {},
   "source": [
    "# LLM Finetuning\n",
    "\n",
    "Data is 10-row sustainability data with prompt+completion.\n",
    "Model is EleutherAI/pythia-70m. We use AutoTokenizer for tokenization and AutoModelForCausalLM for model training. \n",
    "\n",
    "\n",
    "- Data Preparation\n",
    "    - Collect data\n",
    "    - Tokenize data (pad - truncate)\n",
    "    - Split data into train test\n",
    "- Use Base Model\n",
    "- Train\n",
    "    - Train, save model\n",
    "- Inference\n",
    "    - Load model\n",
    "    - Make predictions\n",
    "- Evaluation\n",
    "    - Load model\n",
    "    - Calculate bleu score on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d54f3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f17135",
   "metadata": {},
   "source": [
    "**Collect prompt completion pairs and create a jsonl file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c49ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4c2ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is gender equality?</td>\n",
       "      <td>Gender equality refers to the equal rights, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is gender equality important in the workpl...</td>\n",
       "      <td>Gender equality in the workplace is crucial be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does gender equality benefit society?</td>\n",
       "      <td>Gender equality benefits society by promoting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some common misconceptions about gend...</td>\n",
       "      <td>Some common misconceptions about gender equali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can education play a role in promoting gen...</td>\n",
       "      <td>Education is a powerful tool for promoting gen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0                           What is gender equality?   \n",
       "1  Why is gender equality important in the workpl...   \n",
       "2          How does gender equality benefit society?   \n",
       "3  What are some common misconceptions about gend...   \n",
       "4  How can education play a role in promoting gen...   \n",
       "\n",
       "                                          completion  \n",
       "0  Gender equality refers to the equal rights, re...  \n",
       "1  Gender equality in the workplace is crucial be...  \n",
       "2  Gender equality benefits society by promoting ...  \n",
       "3  Some common misconceptions about gender equali...  \n",
       "4  Education is a powerful tool for promoting gen...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"data_30.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f9b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output JSONL file name\n",
    "filename = 'output.jsonl'\n",
    "\n",
    "# Iterate through the rows and write each row as a JSON object to the JSONL file\n",
    "with open(filename, 'w') as jsonl_file:\n",
    "    for _, row in df.iterrows():\n",
    "        json_data = row.to_json(orient='columns')\n",
    "        jsonl_file.write(json_data + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625c81a",
   "metadata": {},
   "source": [
    "**Create a tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a81c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff8b0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f2d0d",
   "metadata": {},
   "source": [
    "**Tokenize the jsonl data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b612f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    if \"question\" in examples and \"answer\" in examples:\n",
    "        text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "    elif \"input\" in examples and \"output\" in examples:\n",
    "        text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "    elif \"prompt\" in examples and \"completion\" in examples:\n",
    "        text = examples[\"prompt\"][0] + examples[\"completion\"][0]\n",
    "    else:\n",
    "        text = examples[\"text\"][0]\n",
    "\n",
    "    # Add 0 for short sentences\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "    )\n",
    "    \n",
    "    # find the max length after padding, select the min\n",
    "    max_length = min(\n",
    "        tokenized_inputs[\"input_ids\"].shape[1],\n",
    "        2048\n",
    "    )\n",
    "    \n",
    "    # truncate if the sentence is longer than 2048\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7c8829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-47a5361835ced184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:/Users/pelin/.cache/huggingface/datasets/json/default-47a5361835ced184/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe56de0fd774bd9b4e52413b9cb6501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b12a738d144d078174bf9c5dcca2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:/Users/pelin/.cache/huggingface/datasets/json/default-47a5361835ced184/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891fbdf44dda4462b5c88d02503ec70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 30\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "finetuning_dataset_loaded = datasets.load_dataset(\"json\", data_files=filename, split=\"train\")\n",
    "\n",
    "tokenized_dataset = finetuning_dataset_loaded.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    drop_last_batch=True\n",
    ")\n",
    "\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e4b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc766ae",
   "metadata": {},
   "source": [
    "**Analyse tokenized dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43650712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abbb542a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is gender equality?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"prompt\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d18a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gender equality refers to the equal rights, responsibilities, and opportunities of all individuals, regardless of their gender. It implies that the interests, needs, and priorities of both women and men are taken into consideration, recognizing the diversity of different groups of women and men.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"completion\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ffa1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1276,\n",
       " 310,\n",
       " 8645,\n",
       " 13919,\n",
       " 32,\n",
       " 40945,\n",
       " 13919,\n",
       " 10770,\n",
       " 281,\n",
       " 253,\n",
       " 4503,\n",
       " 3570,\n",
       " 13,\n",
       " 19715,\n",
       " 13,\n",
       " 285,\n",
       " 9091,\n",
       " 273,\n",
       " 512,\n",
       " 4292,\n",
       " 13,\n",
       " 10159,\n",
       " 273,\n",
       " 616,\n",
       " 8645,\n",
       " 15,\n",
       " 733,\n",
       " 8018,\n",
       " 326,\n",
       " 253,\n",
       " 6284,\n",
       " 13,\n",
       " 3198,\n",
       " 13,\n",
       " 285,\n",
       " 23971,\n",
       " 273,\n",
       " 1097,\n",
       " 2255,\n",
       " 285,\n",
       " 1821,\n",
       " 403,\n",
       " 2668,\n",
       " 715,\n",
       " 8180,\n",
       " 13,\n",
       " 26182,\n",
       " 253,\n",
       " 9991,\n",
       " 273,\n",
       " 1027,\n",
       " 2390,\n",
       " 273,\n",
       " 2255,\n",
       " 285,\n",
       " 1821,\n",
       " 15]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22992dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"attention_mask\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0689f2a",
   "metadata": {},
   "source": [
    "**Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b1d40d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 27\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
    "print(split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a524574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 27\n",
      "})\n",
      "Dataset({\n",
      "    features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 3\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2483aed8",
   "metadata": {},
   "source": [
    "**Push to hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c12317d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how to push your own dataset to your Huggingface hub\n",
    "# !pip install huggingface_hub\n",
    "# !huggingface-cli login\n",
    "# split_dataset.push_to_hub(dataset_path_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf2c71e",
   "metadata": {},
   "source": [
    "##  Use Base Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73e0b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\transformers\\trainer_pt_utils.py:208: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  device: Optional[torch.device] = torch.device(\"cuda\"),\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import logging\n",
    "import random\n",
    "import logging\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54968bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/pythia-70m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f1a7c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "base_model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2fcf72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): How does gender equality benefit society?\n",
      "Correct answer from docs: Gender equality benefits society by promoting social cohesion, economic growth, and sustainable development. When both men and women have equal opportunities to contribute, societies can tap into a broader range of talents, ideas, and perspectives, leading to more comprehensive solutions to complex challenges.\n",
      "Model's answer: \n",
      "\n",
      "\n",
      "A:\n",
      "\n",
      "The only way to get rid of this is to use the \"gender equality\" option.\n",
      "\n",
      "A:\n",
      "\n",
      "The only way to get rid of this is to use the \"gender equality\" option.\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the \"gender equality\" option.\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the \"gender equality\" option.\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the \"gender equality\n"
     ]
    }
   ],
   "source": [
    "test_text = test_dataset[0]['prompt']\n",
    "max_input_tokens = 1000\n",
    "max_output_tokens=100\n",
    "# Tokenize\n",
    "input_ids = tokenizer.encode(\n",
    "      test_text,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    ")\n",
    "\n",
    "# Generate\n",
    "device = base_model.device\n",
    "generated_tokens_with_prompt = base_model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "\n",
    "# Decode\n",
    "generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "# Strip the prompt\n",
    "generated_text_answer = generated_text_with_prompt[0][len(test_text):]\n",
    "\n",
    "\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from docs: {test_dataset[0]['completion']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(generated_text_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e373b8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73950edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11ebafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 100\n",
    "\n",
    "trained_model_name = f\"lamini_docs_{max_steps}_steps\"\n",
    "output_dir = trained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f48a36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "  # Learning rate\n",
    "  learning_rate=1.0e-5,\n",
    "\n",
    "  # Number of training epochs\n",
    "  num_train_epochs=1,\n",
    "\n",
    "  # Max steps to train for (each step is a batch of data)\n",
    "  # Overrides num_train_epochs, if not -1\n",
    "  max_steps=max_steps,\n",
    "\n",
    "  # Batch size for training\n",
    "  per_device_train_batch_size=1,\n",
    "\n",
    "  # Directory to save model checkpoints\n",
    "  output_dir=output_dir,\n",
    "\n",
    "  # Other arguments\n",
    "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "  disable_tqdm=False, # Disable progress bars\n",
    "  eval_steps=120, # Number of update steps between two evaluations\n",
    "  save_steps=120, # After # steps model is saved\n",
    "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "  evaluation_strategy=\"steps\",\n",
    "  save_strategy=\"steps\",\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=1,\n",
    "  optim=\"adafactor\",\n",
    "  gradient_accumulation_steps = 4,\n",
    "  gradient_checkpointing=False,\n",
    "\n",
    "  # Parameters for early stopping\n",
    "  load_best_model_at_end=True,\n",
    "  save_total_limit=1,\n",
    "  metric_for_best_model=\"eval_loss\",\n",
    "  greater_is_better=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    # model_flops=model_flops,\n",
    "    # total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0148a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPTNeoXForCausalLM.forward` and have been ignored: completion, prompt. If completion, prompt are not expected by `GPTNeoXForCausalLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 27\n",
      "  Num Epochs = 17\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 100\n",
      "  Number of trainable parameters = 70426624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 04:27, Epoch 16/17]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the next line \n",
    "training_output = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc26d08",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c620994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to lamini_docs_100_steps/final\n",
      "Configuration saved in lamini_docs_100_steps/final\\config.json\n",
      "Configuration saved in lamini_docs_100_steps/final\\generation_config.json\n",
      "Model weights saved in lamini_docs_100_steps/final\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: lamini_docs_100_steps/final\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the next 3 lines\n",
    "save_dir = f'{output_dir}/final'\n",
    "trainer.save_model(save_dir)\n",
    "print(\"Saved model to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5173258",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d26364e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file lamini_docs_100_steps/final\\config.json\n",
      "Model config GPTNeoXConfig {\n",
      "  \"_name_or_path\": \"lamini_docs_100_steps/final\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoXForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neox\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"rotary_emb_base\": 10000,\n",
      "  \"rotary_pct\": 0.25,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_parallel_residual\": true,\n",
      "  \"vocab_size\": 50304\n",
      "}\n",
      "\n",
      "loading weights file lamini_docs_100_steps/final\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPTNeoXForCausalLM.\n",
      "\n",
      "All the weights of GPTNeoXForCausalLM were initialized from the model checkpoint at lamini_docs_100_steps/final.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoXForCausalLM for predictions without further training.\n",
      "loading configuration file lamini_docs_100_steps/final\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\pelin/.cache\\huggingface\\hub\\models--EleutherAI--pythia-70m\\snapshots\\2ab25ed47af79376eed2baaf8bbb7a192a0c73ff\\config.json\n",
      "Model config GPTNeoXConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/pythia-70m\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoXForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neox\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"rotary_emb_base\": 10000,\n",
      "  \"rotary_pct\": 0.25,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_parallel_residual\": true,\n",
      "  \"vocab_size\": 50304\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\pelin/.cache\\huggingface\\hub\\models--EleutherAI--pythia-70m\\snapshots\\2ab25ed47af79376eed2baaf8bbb7a192a0c73ff\\model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPTNeoXForCausalLM.\n",
      "\n",
      "All the weights of GPTNeoXForCausalLM were initialized from the model checkpoint at EleutherAI/pythia-70m.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoXForCausalLM for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_steps = 100\n",
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "trained_model_name = f\"lamini_docs_{max_steps}_steps\"\n",
    "output_dir = trained_model_name\n",
    "save_dir = f'{output_dir}/final'\n",
    "\n",
    "\n",
    "\n",
    "finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n",
    "finetuned_slightly_model.to(device) \n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, local_files_only=True)\n",
    "base_model.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82900a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0698add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): How does gender equality benefit society?\n",
      "Correct answer from docs: Gender equality benefits society by promoting social cohesion, economic growth, and sustainable development. When both men and women have equal opportunities to contribute, societies can tap into a broader range of talents, ideas, and perspectives, leading to more comprehensive solutions to complex challenges.\n",
      " \n",
      "Fine-tuned Model's answer: \n",
      "Adefactually,abusive and degrading her traditional gender norms has resulted in a series of drastic changes in society, including gender-based gender reassignment surgery, gender parity surgery, and gender parity-adjustment surgery. By contrast, gender-based gender reassignment surgery has yielded a more equitable and equitable treatment for women and girls, according to the World Health Organization.\n",
      "\n",
      "In 2022, the United Nations General Assembly passed a resolution condemning gender\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "test_question = test_dataset[0]['prompt']\n",
    "print(\"Question input (test):\", test_question)\n",
    "\n",
    "# Tokenize\n",
    "input_ids = tokenizer.encode(\n",
    "      test_question,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    ")\n",
    "\n",
    "# Generate\n",
    "device = finetuned_slightly_model.device\n",
    "generated_tokens_with_prompt = finetuned_slightly_model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "\n",
    "# Decode\n",
    "generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "# Strip the prompt\n",
    "generated_text_answer = generated_text_with_prompt[0][len(test_question):]\n",
    "\n",
    "\n",
    "print(f\"Correct answer from docs: {test_dataset[0]['completion']}\")\n",
    "print(\" \")\n",
    "print(\"Fine-tuned Model's answer: \")\n",
    "print(generated_text_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64632e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model's answer: \n",
      "\n",
      "\n",
      "A:\n",
      "\n",
      "The only way to get rid of this is to use the \"gender equality\" option.\n",
      "\n",
      "A:\n",
      "\n",
      "The only way to get rid of this is to use the \"gender equality\" option.\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the \"gender equality\" option.\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the \"gender equality\" option.\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the \"gender equality\n",
      " \n"
     ]
    }
   ],
   "source": [
    "generated_tokens_with_prompt_base = base_model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "generated_tokens_with_prompt_base = tokenizer.batch_decode(generated_tokens_with_prompt_base, skip_special_tokens=True)\n",
    "generated_text_answer_base = generated_tokens_with_prompt_base[0][len(test_question):]\n",
    "print(\"Base Model's answer: \")\n",
    "print(generated_text_answer_base)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0fff54ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): What is the studies on tech companies in terms of gender equality?\n",
      "Model's answer: \n",
      "Research articles on tech companies in terms of gender equality found that more women are gynaecologists and engineers than ever before. In 2022, tech companies in 2023 reached the top of the female lead in women's tech. And just like most tech companies, tech companies in terms of gender equality are still finding ways to make sure they have the resources they need to fight for gender equality. And just like most tech companies, tech\n"
     ]
    }
   ],
   "source": [
    "# Prediction from scratch\n",
    "test_question = \"What is the studies on tech companies in terms of gender equality?\"\n",
    "print(\"Question input (test):\", test_question)\n",
    "\n",
    "# Tokenize\n",
    "input_ids = tokenizer.encode(\n",
    "      test_question,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    ")\n",
    "\n",
    "# Generate\n",
    "device = finetuned_slightly_model.device\n",
    "generated_tokens_with_prompt = finetuned_slightly_model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "\n",
    "# Decode\n",
    "generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "# Strip the prompt\n",
    "generated_text_answer = generated_text_with_prompt[0][len(test_question):]\n",
    "print(\"Model's answer: \")\n",
    "print(generated_text_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9d4b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model's answer: \n",
      "\n",
      "\n",
      "The research is being conducted in the UK, with the aim of helping to understand the impact of gender equality on the UK’s economy.\n",
      "\n",
      "The research is being conducted in the UK, with the aim of helping to understand the impact of gender equality on the UK’s economy.\n",
      "\n",
      "The research is being conducted in the UK, with the aim of helping to understand the impact of gender equality on the UK’\n",
      " \n"
     ]
    }
   ],
   "source": [
    "generated_tokens_with_prompt_base = base_model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "generated_tokens_with_prompt_base = tokenizer.batch_decode(generated_tokens_with_prompt_base, skip_special_tokens=True)\n",
    "generated_text_answer_base = generated_tokens_with_prompt_base[0][len(test_question):]\n",
    "print(\"Base Model's answer: \")\n",
    "print(generated_text_answer_base)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ec74c",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48ee1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(test_question, model):\n",
    "\n",
    "    # Tokenize\n",
    "    input_ids = tokenizer.encode(\n",
    "          test_question,\n",
    "          return_tensors=\"pt\",\n",
    "          truncation=True,\n",
    "          max_length=max_input_tokens\n",
    "    )\n",
    "\n",
    "    # Generate\n",
    "    device = model.device\n",
    "    generated_tokens_with_prompt = model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "\n",
    "    # Decode\n",
    "    generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "    # Strip the prompt\n",
    "    generated_text_answer = generated_text_with_prompt[0][len(test_question):]\n",
    "    return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e766bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "How does gender equality benefit society?\n",
      "--------------------------------------\n",
      "Actual Completion:\n",
      "Gender equality benefits society by promoting social cohesion, economic growth, and sustainable development. When both men and women have equal opportunities to contribute, societies can tap into a broader range of talents, ideas, and perspectives, leading to more comprehensive solutions to complex challenges.\n",
      "--------------------------------------\n",
      "Fine-tuned prediction\n",
      "Research articles on tech companies in terms of gender equality found that more women are gynaecologists and engineers than ever before. In 2022, tech companies in 2023 reached the top of the female lead in women's tech. And just like most tech companies, tech companies in terms of gender equality are still finding ways to make sure they have the resources they need to fight for gender equality. And just like most tech companies, tech\n",
      "--------------------------------------\n",
      "Base prediction:\n",
      "\n",
      "\n",
      "The research is being conducted in the UK, with the aim of helping to understand the impact of gender equality on the UK’s economy.\n",
      "\n",
      "The research is being conducted in the UK, with the aim of helping to understand the impact of gender equality on the UK’s economy.\n",
      "\n",
      "The research is being conducted in the UK, with the aim of helping to understand the impact of gender equality on the UK’\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_q = test_dataset[0]['prompt']\n",
    "completion_q = test_dataset[0]['completion']\n",
    "predicted_text = generate_output(test_question, finetuned_slightly_model)\n",
    "base_predicted_text = generate_output(test_question, base_model)\n",
    "\n",
    "print('Question:')\n",
    "print(test_q)\n",
    "print(\"--------------------------------------\")\n",
    "print('Actual Completion:')\n",
    "print(completion_q)\n",
    "print(\"--------------------------------------\")\n",
    "print('Fine-tuned prediction')\n",
    "print(predicted_text)\n",
    "print(\"--------------------------------------\")\n",
    "print('Base prediction:')\n",
    "print(base_predicted_text)\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f8b6489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What role do tech companies play in promoting gender equality within the industry?\n",
      "--------------------------------------\n",
      "Actual Completion:\n",
      "Tech companies play a crucial role in shaping industry norms. By implementing inclusive hiring practices, offering mentorship programs, and promoting women in leadership roles, they can set a standard for gender equality. Additionally, by addressing workplace cultures that may perpetuate bias, tech companies can foster more inclusive environments.\n",
      "--------------------------------------\n",
      "Fine-tuned prediction\n",
      "Research articles on tech companies in terms of gender equality found that more women are gynaecologists and engineers than ever before. In 2022, tech companies in 2023 reached the top of the female lead in women's tech. And just like most tech companies, tech companies in terms of gender equality are still finding ways to make sure they have the resources they need to fight for gender equality. And just like most tech companies, tech\n",
      "--------------------------------------\n",
      "Base prediction:\n",
      "\n",
      "\n",
      "The research is being conducted in the UK, with the aim of helping to understand the impact of gender equality on the UK’s economy.\n",
      "\n",
      "The research is being conducted in the UK, with the aim of helping to understand the impact of gender equality on the UK’s economy.\n",
      "\n",
      "The research is being conducted in the UK, with the aim of helping to understand the impact of gender equality on the UK’\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_q = test_dataset[2]['prompt']\n",
    "completion_q = test_dataset[2]['completion']\n",
    "predicted_text = generate_output(test_question, finetuned_slightly_model)\n",
    "base_predicted_text = generate_output(test_question, base_model)\n",
    "\n",
    "print('Question:')\n",
    "print(test_q)\n",
    "print(\"--------------------------------------\")\n",
    "print('Actual Completion:')\n",
    "print(completion_q)\n",
    "print(\"--------------------------------------\")\n",
    "print('Fine-tuned prediction')\n",
    "print(predicted_text)\n",
    "print(\"--------------------------------------\")\n",
    "print('Base prediction:')\n",
    "print(base_predicted_text)\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2e6d411",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Collect the predictions\n",
    "tuned_predicted_text_list = []\n",
    "actual_test_list = []\n",
    "base_predicted_text_list = []\n",
    "for i in range(len(test_dataset)):\n",
    "    test_q = test_dataset[i]['prompt']\n",
    "    completion_q = test_dataset[i]['completion']\n",
    "    predicted_text = generate_output(test_question, finetuned_slightly_model)\n",
    "    base_predicted_text = generate_output(test_question, base_model)\n",
    "    actual_test_list.append(completion_q)\n",
    "    tuned_predicted_text_list.append(predicted_text)\n",
    "    base_predicted_text_list.append(base_predicted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01422d12",
   "metadata": {},
   "source": [
    "**Calculate the bleu score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c3e53fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Predictions Results\n",
      "{'bleu': 0.0, 'precisions': [0.12280701754385964, 0.0044444444444444444, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.5724137931034483, 'translation_length': 228, 'reference_length': 145}\n",
      "Fine Tuned Model Predictions Results\n",
      "{'bleu': 0.022615029629288786, 'precisions': [0.1934156378600823, 0.025, 0.012658227848101266, 0.004273504273504274], 'brevity_penalty': 1.0, 'length_ratio': 1.6758620689655173, 'translation_length': 243, 'reference_length': 145}\n"
     ]
    }
   ],
   "source": [
    "# !pip install evaluate\n",
    "\n",
    "import evaluate\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "results = bleu.compute(predictions=base_predicted_text_list, references=actual_test_list)\n",
    "print(\"Base Model Predictions Results\")\n",
    "print(results)\n",
    "\n",
    "results = bleu.compute(predictions=tuned_predicted_text_list, references=actual_test_list)\n",
    "print(\"Fine Tuned Model Predictions Results\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d937fdfb",
   "metadata": {},
   "source": [
    "## Examine the Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c092a8",
   "metadata": {},
   "source": [
    "**How to read the jsonl file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b903c668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is gender equality?</td>\n",
       "      <td>Gender equality refers to the equal rights, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is gender equality important in the workpl...</td>\n",
       "      <td>Gender equality in the workplace is crucial be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does gender equality benefit society?</td>\n",
       "      <td>Gender equality benefits society by promoting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some common misconceptions about gend...</td>\n",
       "      <td>Some common misconceptions about gender equali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can education play a role in promoting gen...</td>\n",
       "      <td>Education is a powerful tool for promoting gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the difference between gender equality...</td>\n",
       "      <td>While both terms aim for fairness, gender equa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do cultural norms impact gender equality?</td>\n",
       "      <td>Cultural norms play a significant role in shap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Why is it essential to involve men and boys in...</td>\n",
       "      <td>Involving men and boys in the fight for gender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does gender equality relate to other forms...</td>\n",
       "      <td>Gender equality is interconnected with other f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are some actionable steps individuals can...</td>\n",
       "      <td>Individuals can promote gender equality by edu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does media representation impact perceptio...</td>\n",
       "      <td>Media representation significantly influences ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What role do governments play in ensuring gend...</td>\n",
       "      <td>Governments play a pivotal role in ensuring ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How does economic empowerment relate to gender...</td>\n",
       "      <td>Economic empowerment is a cornerstone of gende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What challenges do LGBTQ+ individuals face in ...</td>\n",
       "      <td>LGBTQ+ individuals often face unique challenge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How can organizations foster a culture of gend...</td>\n",
       "      <td>Organizations can foster a culture of gender e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What is the significance of intersectionality ...</td>\n",
       "      <td>Intersectionality recognizes that individuals ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How do patriarchal societies impact the progre...</td>\n",
       "      <td>Patriarchal societies, where male dominance is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Why is it essential to have gender-sensitive p...</td>\n",
       "      <td>Gender-sensitive policies ensure that the diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What role do tech companies play in promoting ...</td>\n",
       "      <td>Tech companies play a crucial role in shaping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What challenges do women face in the tech indu...</td>\n",
       "      <td>Women in the tech industry often face challeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How can online platforms be made safer for wom...</td>\n",
       "      <td>Online platforms can enhance safety by impleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Why is it crucial to address gender biases in ...</td>\n",
       "      <td>Addressing gender biases in AI and ML is vital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What is the importance of gender equality?</td>\n",
       "      <td>Gender equality is important because it is a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What are some recent trends and statistics tha...</td>\n",
       "      <td>More women are holding positions of leadershi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\nWhat is the current status of girls' educati...</td>\n",
       "      <td>More girls are attending school and completing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>How has the economic empowerment of women evol...</td>\n",
       "      <td>Women are becoming more economically empowered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\nWhat is the latest global initiative aimed a...</td>\n",
       "      <td>There is a growing global movement to end viol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\nWhat is the key finding of the World Economi...</td>\n",
       "      <td>The World Economic Forum's Global Gender Gap R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Which countries have seen an increase in the n...</td>\n",
       "      <td>In 2023, there are more women serving as heads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What are the benefits of having more women in ...</td>\n",
       "      <td>Studies have shown that companies with more w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0                            What is gender equality?   \n",
       "1   Why is gender equality important in the workpl...   \n",
       "2           How does gender equality benefit society?   \n",
       "3   What are some common misconceptions about gend...   \n",
       "4   How can education play a role in promoting gen...   \n",
       "5   What is the difference between gender equality...   \n",
       "6       How do cultural norms impact gender equality?   \n",
       "7   Why is it essential to involve men and boys in...   \n",
       "8   How does gender equality relate to other forms...   \n",
       "9   What are some actionable steps individuals can...   \n",
       "10  How does media representation impact perceptio...   \n",
       "11  What role do governments play in ensuring gend...   \n",
       "12  How does economic empowerment relate to gender...   \n",
       "13  What challenges do LGBTQ+ individuals face in ...   \n",
       "14  How can organizations foster a culture of gend...   \n",
       "15  What is the significance of intersectionality ...   \n",
       "16  How do patriarchal societies impact the progre...   \n",
       "17  Why is it essential to have gender-sensitive p...   \n",
       "18  What role do tech companies play in promoting ...   \n",
       "19  What challenges do women face in the tech indu...   \n",
       "20  How can online platforms be made safer for wom...   \n",
       "21  Why is it crucial to address gender biases in ...   \n",
       "22         What is the importance of gender equality?   \n",
       "23  What are some recent trends and statistics tha...   \n",
       "24  \\nWhat is the current status of girls' educati...   \n",
       "25  How has the economic empowerment of women evol...   \n",
       "26  \\nWhat is the latest global initiative aimed a...   \n",
       "27  \\nWhat is the key finding of the World Economi...   \n",
       "28  Which countries have seen an increase in the n...   \n",
       "29  What are the benefits of having more women in ...   \n",
       "\n",
       "                                           completion  \n",
       "0   Gender equality refers to the equal rights, re...  \n",
       "1   Gender equality in the workplace is crucial be...  \n",
       "2   Gender equality benefits society by promoting ...  \n",
       "3   Some common misconceptions about gender equali...  \n",
       "4   Education is a powerful tool for promoting gen...  \n",
       "5   While both terms aim for fairness, gender equa...  \n",
       "6   Cultural norms play a significant role in shap...  \n",
       "7   Involving men and boys in the fight for gender...  \n",
       "8   Gender equality is interconnected with other f...  \n",
       "9   Individuals can promote gender equality by edu...  \n",
       "10  Media representation significantly influences ...  \n",
       "11  Governments play a pivotal role in ensuring ge...  \n",
       "12  Economic empowerment is a cornerstone of gende...  \n",
       "13  LGBTQ+ individuals often face unique challenge...  \n",
       "14  Organizations can foster a culture of gender e...  \n",
       "15  Intersectionality recognizes that individuals ...  \n",
       "16  Patriarchal societies, where male dominance is...  \n",
       "17  Gender-sensitive policies ensure that the diff...  \n",
       "18  Tech companies play a crucial role in shaping ...  \n",
       "19  Women in the tech industry often face challeng...  \n",
       "20  Online platforms can enhance safety by impleme...  \n",
       "21  Addressing gender biases in AI and ML is vital...  \n",
       "22  Gender equality is important because it is a h...  \n",
       "23   More women are holding positions of leadershi...  \n",
       "24  More girls are attending school and completing...  \n",
       "25  Women are becoming more economically empowered...  \n",
       "26  There is a growing global movement to end viol...  \n",
       "27  The World Economic Forum's Global Gender Gap R...  \n",
       "28  In 2023, there are more women serving as heads...  \n",
       "29   Studies have shown that companies with more w...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction_dataset_df = pd.read_json(filename, lines=True)\n",
    "instruction_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c503577",
   "metadata": {},
   "source": [
    "**Turn the file into dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0286ec60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'What is gender equality?',\n",
       " 1: 'Why is gender equality important in the workplace?',\n",
       " 2: 'How does gender equality benefit society?',\n",
       " 3: 'What are some common misconceptions about gender equality?',\n",
       " 4: 'How can education play a role in promoting gender equality?',\n",
       " 5: 'What is the difference between gender equality and gender equity?',\n",
       " 6: 'How do cultural norms impact gender equality?',\n",
       " 7: 'Why is it essential to involve men and boys in the fight for gender equality?',\n",
       " 8: 'How does gender equality relate to other forms of equality?',\n",
       " 9: 'What are some actionable steps individuals can take to promote gender equality in their communities?',\n",
       " 10: 'How does media representation impact perceptions of gender roles?',\n",
       " 11: 'What role do governments play in ensuring gender equality?',\n",
       " 12: 'How does economic empowerment relate to gender equality?',\n",
       " 13: 'What challenges do LGBTQ+ individuals face in the context of gender equality?',\n",
       " 14: 'How can organizations foster a culture of gender equality?',\n",
       " 15: 'What is the significance of intersectionality in discussions about gender equality?',\n",
       " 16: 'How do patriarchal societies impact the progress of gender equality?',\n",
       " 17: 'Why is it essential to have gender-sensitive policies in place?',\n",
       " 18: 'What role do tech companies play in promoting gender equality within the industry?',\n",
       " 19: 'What challenges do women face in the tech industry, and how can they be addressed?',\n",
       " 20: 'How can online platforms be made safer for women and marginalized genders?',\n",
       " 21: 'Why is it crucial to address gender biases in artificial intelligence and machine learning?',\n",
       " 22: 'What is the importance of gender equality?',\n",
       " 23: 'What are some recent trends and statistics that highlight the increasing presence of women in leadership roles in both business and government, particularly in the United States?',\n",
       " 24: \"\\nWhat is the current status of girls' education worldwide, including the achievement of gender parity at the primary level and the increasing likelihood of girls attending secondary school compared to boys in various countries, as of 2022?\",\n",
       " 25: 'How has the economic empowerment of women evolved recently?',\n",
       " 26: '\\nWhat is the latest global initiative aimed at addressing violence against women and girls, and when was it launched by the United Nations in 2023?',\n",
       " 27: \"\\nWhat is the key finding of the World Economic Forum's Global Gender Gap Report for 2023 regarding the status of the global gender gap?\",\n",
       " 28: 'Which countries have seen an increase in the number of women serving as heads of state or government in 2023?',\n",
       " 29: 'What are the benefits of having more women in leadership positions?'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = instruction_dataset_df.to_dict()\n",
    "examples['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54d7c56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is gender equality?',\n",
       " 'Why is gender equality important in the workplace?',\n",
       " 'How does gender equality benefit society?',\n",
       " 'What are some common misconceptions about gender equality?',\n",
       " 'How can education play a role in promoting gender equality?',\n",
       " 'What is the difference between gender equality and gender equity?',\n",
       " 'How do cultural norms impact gender equality?',\n",
       " 'Why is it essential to involve men and boys in the fight for gender equality?',\n",
       " 'How does gender equality relate to other forms of equality?',\n",
       " 'What are some actionable steps individuals can take to promote gender equality in their communities?',\n",
       " 'How does media representation impact perceptions of gender roles?',\n",
       " 'What role do governments play in ensuring gender equality?',\n",
       " 'How does economic empowerment relate to gender equality?',\n",
       " 'What challenges do LGBTQ+ individuals face in the context of gender equality?',\n",
       " 'How can organizations foster a culture of gender equality?',\n",
       " 'What is the significance of intersectionality in discussions about gender equality?',\n",
       " 'How do patriarchal societies impact the progress of gender equality?',\n",
       " 'Why is it essential to have gender-sensitive policies in place?',\n",
       " 'What role do tech companies play in promoting gender equality within the industry?',\n",
       " 'What challenges do women face in the tech industry, and how can they be addressed?',\n",
       " 'How can online platforms be made safer for women and marginalized genders?',\n",
       " 'Why is it crucial to address gender biases in artificial intelligence and machine learning?',\n",
       " 'What is the importance of gender equality?',\n",
       " 'What are some recent trends and statistics that highlight the increasing presence of women in leadership roles in both business and government, particularly in the United States?',\n",
       " \"\\nWhat is the current status of girls' education worldwide, including the achievement of gender parity at the primary level and the increasing likelihood of girls attending secondary school compared to boys in various countries, as of 2022?\",\n",
       " 'How has the economic empowerment of women evolved recently?',\n",
       " '\\nWhat is the latest global initiative aimed at addressing violence against women and girls, and when was it launched by the United Nations in 2023?',\n",
       " \"\\nWhat is the key finding of the World Economic Forum's Global Gender Gap Report for 2023 regarding the status of the global gender gap?\",\n",
       " 'Which countries have seen an increase in the number of women serving as heads of state or government in 2023?',\n",
       " 'What are the benefits of having more women in leadership positions?']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuning_dataset_loaded['prompt']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
