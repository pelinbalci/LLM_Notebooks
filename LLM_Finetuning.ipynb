{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca31e44",
   "metadata": {},
   "source": [
    "# LLM Finetuning\n",
    "\n",
    "Data is 10-row sustainability data with prompt+completion.\n",
    "Model is EleutherAI/pythia-70m. We use AutoTokenizer for tokenization and AutoModelForCausalLM for model training. \n",
    "\n",
    "\n",
    "- Data Preparation\n",
    "    - Collect data\n",
    "    - Tokenize data (pad - truncate)\n",
    "    - Split data into train test\n",
    "- Use Base Model\n",
    "- Train\n",
    "    - Train, save model\n",
    "- Inference\n",
    "    - Load model\n",
    "    - Make predictions\n",
    "- Evaluation\n",
    "    - Load model\n",
    "    - Calculate bleu score on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d54f3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f17135",
   "metadata": {},
   "source": [
    "**Collect prompt completion pairs and create a jsonl file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c49ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4c2ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is sustainability important?</td>\n",
       "      <td>Sustainability is crucial because it ensures a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can individuals contribute to sustainability?</td>\n",
       "      <td>Individuals can contribute to sustainability b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are some sustainable practices in agricul...</td>\n",
       "      <td>Sustainable agriculture practices include crop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe the concept of a circular economy.</td>\n",
       "      <td>A circular economy is an economic model that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does climate change relate to sustainability?</td>\n",
       "      <td>Climate change is a major threat to sustainabi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0                   Why is sustainability important?   \n",
       "1  How can individuals contribute to sustainability?   \n",
       "2  What are some sustainable practices in agricul...   \n",
       "3        Describe the concept of a circular economy.   \n",
       "4  How does climate change relate to sustainability?   \n",
       "\n",
       "                                          completion  \n",
       "0  Sustainability is crucial because it ensures a...  \n",
       "1  Individuals can contribute to sustainability b...  \n",
       "2  Sustainable agriculture practices include crop...  \n",
       "3  A circular economy is an economic model that a...  \n",
       "4  Climate change is a major threat to sustainabi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"data_10.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f9b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output JSONL file name\n",
    "filename = 'output.jsonl'\n",
    "\n",
    "# Iterate through the rows and write each row as a JSON object to the JSONL file\n",
    "with open(filename, 'w') as jsonl_file:\n",
    "    for _, row in df.iterrows():\n",
    "        json_data = row.to_json(orient='columns')\n",
    "        jsonl_file.write(json_data + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625c81a",
   "metadata": {},
   "source": [
    "**Create a tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a81c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff8b0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f2d0d",
   "metadata": {},
   "source": [
    "**Tokenize the jsonl data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b612f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    if \"question\" in examples and \"answer\" in examples:\n",
    "        text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "    elif \"input\" in examples and \"output\" in examples:\n",
    "        text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "    elif \"prompt\" in examples and \"completion\" in examples:\n",
    "        text = examples[\"prompt\"][0] + examples[\"completion\"][0]\n",
    "    else:\n",
    "        text = examples[\"text\"][0]\n",
    "\n",
    "    # Add 0 for short sentences\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "    )\n",
    "    \n",
    "    # find the max length after padding, select the min\n",
    "    max_length = min(\n",
    "        tokenized_inputs[\"input_ids\"].shape[1],\n",
    "        2048\n",
    "    )\n",
    "    \n",
    "    # truncate if the sentence is longer than 2048\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7c8829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4d19725dae09d542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:/Users/pelin/.cache/huggingface/datasets/json/default-4d19725dae09d542/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553e1672b4424969b8dc51ab9c258739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831041f387a3409694a9ff907272b68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:/Users/pelin/.cache/huggingface/datasets/json/default-4d19725dae09d542/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c561ed5deab40f49c3807ea9c54302d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "finetuning_dataset_loaded = datasets.load_dataset(\"json\", data_files=filename, split=\"train\")\n",
    "\n",
    "tokenized_dataset = finetuning_dataset_loaded.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    drop_last_batch=True\n",
    ")\n",
    "\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e4b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc766ae",
   "metadata": {},
   "source": [
    "**Analyse tokenized dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43650712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abbb542a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why is sustainability important?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"prompt\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d18a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sustainability is crucial because it ensures a balance between meeting our current needs and preserving resources for future generations.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"completion\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ffa1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4967,\n",
       " 310,\n",
       " 32435,\n",
       " 1774,\n",
       " 32,\n",
       " 52,\n",
       " 28216,\n",
       " 1430,\n",
       " 310,\n",
       " 9560,\n",
       " 984,\n",
       " 352,\n",
       " 20096,\n",
       " 247,\n",
       " 6654,\n",
       " 875,\n",
       " 4804,\n",
       " 776,\n",
       " 1655,\n",
       " 3198,\n",
       " 285,\n",
       " 24279,\n",
       " 5300,\n",
       " 323,\n",
       " 2852,\n",
       " 14649,\n",
       " 15]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22992dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"attention_mask\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0689f2a",
   "metadata": {},
   "source": [
    "**Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b1d40d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 9\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
    "print(split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a524574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 9\n",
      "})\n",
      "Dataset({\n",
      "    features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2483aed8",
   "metadata": {},
   "source": [
    "**Push to hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c12317d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how to push your own dataset to your Huggingface hub\n",
    "# !pip install huggingface_hub\n",
    "# !huggingface-cli login\n",
    "# split_dataset.push_to_hub(dataset_path_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf2c71e",
   "metadata": {},
   "source": [
    "##  Use Base Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73e0b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\transformers\\trainer_pt_utils.py:208: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  device: Optional[torch.device] = torch.device(\"cuda\"),\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import logging\n",
    "import random\n",
    "import logging\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54968bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/pythia-70m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f1a7c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "base_model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2fcf72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): What is the triple bottom line concept in sustainability?\n",
      "Correct answer from docs: The triple bottom line concept in sustainability evaluates the performance of organizations or projects based on three criteria: social, environmental, and economic, emphasizing a holistic approach to success.\n",
      "Model's answer: \n",
      "\n",
      "\n",
      "A:\n",
      "\n",
      "The answer is that you need to be able to use the following two concepts:\n",
      "\n",
      "The first is the definition of the bottom line concept.\n",
      "The second is the definition of the bottom line concept.\n",
      "The third is the definition of the bottom line concept.\n",
      "The fourth is the definition of the bottom line concept.\n",
      "The fourth is the definition of the bottom line concept.\n",
      "The fifth is the definition of\n"
     ]
    }
   ],
   "source": [
    "test_text = test_dataset[0]['prompt']\n",
    "max_input_tokens = 1000\n",
    "max_output_tokens=100\n",
    "# Tokenize\n",
    "input_ids = tokenizer.encode(\n",
    "      test_text,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    ")\n",
    "\n",
    "# Generate\n",
    "device = base_model.device\n",
    "generated_tokens_with_prompt = base_model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "\n",
    "# Decode\n",
    "generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "# Strip the prompt\n",
    "generated_text_answer = generated_text_with_prompt[0][len(test_text):]\n",
    "\n",
    "\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from docs: {test_dataset[0]['completion']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(generated_text_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e373b8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73950edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11ebafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 30\n",
    "\n",
    "trained_model_name = f\"lamini_docs_{max_steps}_steps\"\n",
    "output_dir = trained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f48a36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "  # Learning rate\n",
    "  learning_rate=1.0e-5,\n",
    "\n",
    "  # Number of training epochs\n",
    "  num_train_epochs=1,\n",
    "\n",
    "  # Max steps to train for (each step is a batch of data)\n",
    "  # Overrides num_train_epochs, if not -1\n",
    "  max_steps=max_steps,\n",
    "\n",
    "  # Batch size for training\n",
    "  per_device_train_batch_size=1,\n",
    "\n",
    "  # Directory to save model checkpoints\n",
    "  output_dir=output_dir,\n",
    "\n",
    "  # Other arguments\n",
    "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "  disable_tqdm=False, # Disable progress bars\n",
    "  eval_steps=120, # Number of update steps between two evaluations\n",
    "  save_steps=120, # After # steps model is saved\n",
    "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "  evaluation_strategy=\"steps\",\n",
    "  save_strategy=\"steps\",\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=1,\n",
    "  optim=\"adafactor\",\n",
    "  gradient_accumulation_steps = 4,\n",
    "  gradient_checkpointing=False,\n",
    "\n",
    "  # Parameters for early stopping\n",
    "  load_best_model_at_end=True,\n",
    "  save_total_limit=1,\n",
    "  metric_for_best_model=\"eval_loss\",\n",
    "  greater_is_better=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    # model_flops=model_flops,\n",
    "    # total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0148a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line \n",
    "# training_output = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc26d08",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c620994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next 3 lines\n",
    "# save_dir = f'{output_dir}/final'\n",
    "# trainer.save_model(save_dir)\n",
    "# print(\"Saved model to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5173258",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d26364e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file lamini_docs_30_steps/final\\config.json\n",
      "Model config GPTNeoXConfig {\n",
      "  \"_name_or_path\": \"lamini_docs_30_steps/final\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoXForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neox\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"rotary_emb_base\": 10000,\n",
      "  \"rotary_pct\": 0.25,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_parallel_residual\": true,\n",
      "  \"vocab_size\": 50304\n",
      "}\n",
      "\n",
      "loading weights file lamini_docs_30_steps/final\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPTNeoXForCausalLM.\n",
      "\n",
      "All the weights of GPTNeoXForCausalLM were initialized from the model checkpoint at lamini_docs_30_steps/final.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoXForCausalLM for predictions without further training.\n",
      "loading configuration file lamini_docs_30_steps/final\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_steps = 30\n",
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "trained_model_name = f\"lamini_docs_{max_steps}_steps\"\n",
    "output_dir = trained_model_name\n",
    "save_dir = f'{output_dir}/final'\n",
    "\n",
    "\n",
    "\n",
    "finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n",
    "finetuned_slightly_model.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82900a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0698add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): What is the triple bottom line concept in sustainability?\n",
      "Correct answer from docs: The triple bottom line concept in sustainability evaluates the performance of organizations or projects based on three criteria: social, environmental, and economic, emphasizing a holistic approach to success.\n",
      " \n",
      "Model's answer: \n",
      "Sustainability is a major challenge in sustainability as it provides a means for reducing waste, recycling, and conserving resources.Renewable energy sources like solar, wind, and geothermal energy play a vital role in sustainability as it provides a means for reducing waste, recycling, and conserving resources.Sustainable sustainability is essential for sustainability as it provides a means for reducing waste, recycling, recycling, and conserving resources.Sustainable sustainability is\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "test_question = test_dataset[0]['prompt']\n",
    "print(\"Question input (test):\", test_question)\n",
    "\n",
    "# Tokenize\n",
    "input_ids = tokenizer.encode(\n",
    "      test_question,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    ")\n",
    "\n",
    "# Generate\n",
    "device = finetuned_slightly_model.device\n",
    "generated_tokens_with_prompt = finetuned_slightly_model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "\n",
    "# Decode\n",
    "generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "# Strip the prompt\n",
    "generated_text_answer = generated_text_with_prompt[0][len(test_question):]\n",
    "\n",
    "\n",
    "print(f\"Correct answer from docs: {test_dataset[0]['completion']}\")\n",
    "print(\" \")\n",
    "print(\"Model's answer: \")\n",
    "print(generated_text_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fff54ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): Can you describe sustainability\n",
      "Model's answer: \n",
      " as a concept, considering the sustainability of sustainability as a concept in sustainability.A sustainability concept is a concept that aims to minimize waste, promote sustainability, promote sustainability, and promote sustainability by designing, preserving, and conserving resources for human survival.Sustainable sustainability is a concept that aims to minimize waste, promote sustainability, promote sustainability, and promote sustainability by designing, preserving, and conserving resources for human survival.Sustainable sustainability is a concept that aims to minimize waste, promote\n"
     ]
    }
   ],
   "source": [
    "# Prediction from scratch\n",
    "test_question = \"Can you describe sustainability\"\n",
    "print(\"Question input (test):\", test_question)\n",
    "\n",
    "# Tokenize\n",
    "input_ids = tokenizer.encode(\n",
    "      test_question,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    ")\n",
    "\n",
    "# Generate\n",
    "device = finetuned_slightly_model.device\n",
    "generated_tokens_with_prompt = finetuned_slightly_model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "\n",
    "# Decode\n",
    "generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "# Strip the prompt\n",
    "generated_text_answer = generated_text_with_prompt[0][len(test_question):]\n",
    "print(\"Model's answer: \")\n",
    "print(generated_text_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ec74c",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48ee1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(test_question, model):\n",
    "\n",
    "    # Tokenize\n",
    "    input_ids = tokenizer.encode(\n",
    "          test_question,\n",
    "          return_tensors=\"pt\",\n",
    "          truncation=True,\n",
    "          max_length=max_input_tokens\n",
    "    )\n",
    "\n",
    "    # Generate\n",
    "    device = model.device\n",
    "    generated_tokens_with_prompt = model.generate(input_ids=input_ids.to(device), max_length=max_output_tokens)\n",
    "\n",
    "    # Decode\n",
    "    generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "    # Strip the prompt\n",
    "    generated_text_answer = generated_text_with_prompt[0][len(test_question):]\n",
    "    return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e766bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuned model:  Sustainability is a major challenge in sustainability as it provides a means for reducing waste, recycling, and conserving resources.Renewable energy sources like solar, wind, and geothermal energy play a vital role in sustainability as it provides a means for reducing waste, recycling, and conserving resources.Sustainable sustainability is essential for sustainability as it provides a means for reducing waste, recycling, recycling, and conserving resources.Sustainable sustainability is\n",
      "Base model:  \n",
      "\n",
      "A:\n",
      "\n",
      "The answer is that you need to be able to use the following two concepts:\n",
      "\n",
      "The first is the definition of the bottom line concept.\n",
      "The second is the definition of the bottom line concept.\n",
      "The third is the definition of the bottom line concept.\n",
      "The fourth is the definition of the bottom line concept.\n",
      "The fourth is the definition of the bottom line concept.\n",
      "The fifth is the definition of\n",
      "Actual Answer:  The triple bottom line concept in sustainability evaluates the performance of organizations or projects based on three criteria: social, environmental, and economic, emphasizing a holistic approach to success.\n"
     ]
    }
   ],
   "source": [
    "# control the function\n",
    "test_question = test_dataset[0]['prompt']\n",
    "print('Fine tuned model: ', generate_output(test_question, finetuned_slightly_model))\n",
    "print('Base model: ', generate_output(test_question, base_model))\n",
    "print('Actual Answer: ', test_dataset[0]['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2e6d411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Collect the predictions\n",
    "tuned_predicted_text_list = []\n",
    "actual_test_list = []\n",
    "base_predicted_text_list = []\n",
    "for i in range(len(test_dataset)):\n",
    "    test_q = test_dataset[i]['prompt']\n",
    "    completion_q = test_dataset[i]['completion']\n",
    "    predicted_text = generate_output(test_question, finetuned_slightly_model)\n",
    "    base_predicted_text = generate_output(test_question, base_model)\n",
    "    actual_test_list.append(completion_q)\n",
    "    tuned_predicted_text_list.append(predicted_text)\n",
    "    base_predicted_text_list.append(base_predicted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01422d12",
   "metadata": {},
   "source": [
    "**Calculate the bleu score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c3e53fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Predictions Results\n",
      "{'bleu': 0.0, 'precisions': [0.11392405063291139, 0.02564102564102564, 0.012987012987012988, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 2.393939393939394, 'translation_length': 79, 'reference_length': 33}\n",
      "Fine Tuned Model Predictions Results\n",
      "{'bleu': 0.0, 'precisions': [0.1, 0.02531645569620253, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 2.4242424242424243, 'translation_length': 80, 'reference_length': 33}\n"
     ]
    }
   ],
   "source": [
    "# !pip install evaluate\n",
    "\n",
    "import evaluate\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "results = bleu.compute(predictions=base_predicted_text_list, references=actual_test_list)\n",
    "print(\"Base Model Predictions Results\")\n",
    "print(results)\n",
    "\n",
    "results = bleu.compute(predictions=tuned_predicted_text_list, references=actual_test_list)\n",
    "print(\"Fine Tuned Model Predictions Results\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d937fdfb",
   "metadata": {},
   "source": [
    "## Examine the Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c092a8",
   "metadata": {},
   "source": [
    "**How to read the jsonl file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b903c668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is sustainability important?</td>\n",
       "      <td>Sustainability is crucial because it ensures a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can individuals contribute to sustainability?</td>\n",
       "      <td>Individuals can contribute to sustainability b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are some sustainable practices in agricul...</td>\n",
       "      <td>Sustainable agriculture practices include crop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe the concept of a circular economy.</td>\n",
       "      <td>A circular economy is an economic model that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does climate change relate to sustainability?</td>\n",
       "      <td>Climate change is a major threat to sustainabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the benefits of sustainable transport...</td>\n",
       "      <td>Sustainable transportation, such as public tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explain the role of renewable energy in sustai...</td>\n",
       "      <td>Renewable energy sources like solar, wind, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the triple bottom line concept in sust...</td>\n",
       "      <td>The triple bottom line concept in sustainabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How can businesses integrate sustainability in...</td>\n",
       "      <td>Businesses can integrate sustainability by ado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Discuss the connection between biodiversity an...</td>\n",
       "      <td>Biodiversity is essential for sustainability a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0                   Why is sustainability important?   \n",
       "1  How can individuals contribute to sustainability?   \n",
       "2  What are some sustainable practices in agricul...   \n",
       "3        Describe the concept of a circular economy.   \n",
       "4  How does climate change relate to sustainability?   \n",
       "5  What are the benefits of sustainable transport...   \n",
       "6  Explain the role of renewable energy in sustai...   \n",
       "7  What is the triple bottom line concept in sust...   \n",
       "8  How can businesses integrate sustainability in...   \n",
       "9  Discuss the connection between biodiversity an...   \n",
       "\n",
       "                                          completion  \n",
       "0  Sustainability is crucial because it ensures a...  \n",
       "1  Individuals can contribute to sustainability b...  \n",
       "2  Sustainable agriculture practices include crop...  \n",
       "3  A circular economy is an economic model that a...  \n",
       "4  Climate change is a major threat to sustainabi...  \n",
       "5  Sustainable transportation, such as public tra...  \n",
       "6  Renewable energy sources like solar, wind, and...  \n",
       "7  The triple bottom line concept in sustainabili...  \n",
       "8  Businesses can integrate sustainability by ado...  \n",
       "9  Biodiversity is essential for sustainability a...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction_dataset_df = pd.read_json(filename, lines=True)\n",
    "instruction_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c503577",
   "metadata": {},
   "source": [
    "**Turn the file into dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0286ec60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Why is sustainability important?',\n",
       " 1: 'How can individuals contribute to sustainability?',\n",
       " 2: 'What are some sustainable practices in agriculture?',\n",
       " 3: 'Describe the concept of a circular economy.',\n",
       " 4: 'How does climate change relate to sustainability?',\n",
       " 5: 'What are the benefits of sustainable transportation?',\n",
       " 6: 'Explain the role of renewable energy in sustainability.',\n",
       " 7: 'What is the triple bottom line concept in sustainability?',\n",
       " 8: 'How can businesses integrate sustainability into their operations?',\n",
       " 9: 'Discuss the connection between biodiversity and sustainability.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = instruction_dataset_df.to_dict()\n",
    "examples['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54d7c56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why is sustainability important?',\n",
       " 'How can individuals contribute to sustainability?',\n",
       " 'What are some sustainable practices in agriculture?',\n",
       " 'Describe the concept of a circular economy.',\n",
       " 'How does climate change relate to sustainability?',\n",
       " 'What are the benefits of sustainable transportation?',\n",
       " 'Explain the role of renewable energy in sustainability.',\n",
       " 'What is the triple bottom line concept in sustainability?',\n",
       " 'How can businesses integrate sustainability into their operations?',\n",
       " 'Discuss the connection between biodiversity and sustainability.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuning_dataset_loaded['prompt']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
